[TRAINING]
val_dataset_path = "/mnt/data5/multi_tracking/pstudio_easy"
kubric_dir = /mnt/data5/multi_tracking/kub_mul_256_0731
precision = bf16-mixed
batch_size = 1
val_check_interval = 1.0
log_every_n_steps = 5
gradient_clip_val = 1.0
max_steps = 100000
query_first = True
lora_usage = False
crop_size = 256
seq_len=24
traj_per_sample = 256
use_augs = False
vggt_size = 256

[MODEL]
model_kwargs = {"window_len": 16, "stride": 4, "corr_radius": 3, "corr_levels": 4, "num_virtual_tracks": 64,
                "model_resolution": 256, "add_space_attn": True, "linear_layer_for_vis_conf": True, "lora_model": None, "use_checkpoint": True}
model_forward_kwargs = {"iters": 4, "is_train": True}

[LORA]
lora_kwargs = {'lora_path': '/mnt/data5/multi_tracking/vggt/model.pt','lora_rank': 8}


[LOSS]
loss_name = track_loss
eval_loss_name = track_loss
loss_kwargs = {}

[OPTIMIZER]
optimizer_name = AdamW
optimizer_kwargs = {"lr": 5e-4, "wdecay": 5e-4, "eps":1e-8}

[SCHEDULER]
schdular_name = OneCycleLR
scheduler_kwargs = {"pct_start": 0.05, "cycle_momentum": False, "anneal_strategy": "cos"}
